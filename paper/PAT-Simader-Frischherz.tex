% ViT 2x on-write make
% Authors: Marcel Simader (marcel.simader@jku.at)
%          Melissa Frischherz (melissa.frischherz@gmail.com)
% Date: 20.03.2024
\documentclass[conference]{IEEEtran}

% Preamble {{{
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~ Preamble ~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[dvipsnames]{xcolor}

\usepackage{cite}
\bibliographystyle{./IEEEtran}

% ~~~~~~~~~~~~~~~~~~~~ Custom Packages ~~~~~~~~~~~~~~~~~~~~

\usepackage{xspace}
\usepackage{tikz}
\usepackage{pgfplots}

% ~~~~~~~~~~~~~~~~~~~~ Custom Commands ~~~~~~~~~~~~~~~~~~~~

\newcommand{\TODO}[1]{\textbf{\textcolor{Bittersweet}{#1}}\xspace}
\newcommand{\TODOM}[1]{\TODO{\emph{TODO}: #1}\xspace}
\newcommand{\TODOB}{\TODO{\emph{TODO}}\xspace}

% ~~~~~~~~~~~~~~~~~~~~ Custom Settings ~~~~~~~~~~~~~~~~~~~~

\graphicspath{./figures}

% }}}

% Document {{{
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~ Document ~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\begin{document}

% Title {{{
% ~~~~~~~~~~~~~~~~~~~~ Title ~~~~~~~~~~~~~~~~~~~~
\title{Exploring Existing Machine Learning Approaches Discerning the Quality of Source
Code Identifiers}

\author{\IEEEauthorblockN{Marcel Simader}
\IEEEauthorblockA{\textit{AI for Software Engineering, Topic 3} \\
\textit{k11823075 \textfractionsolidus{} SKZ 521}\\
marcel.simader@jku.at}
\and
\IEEEauthorblockN{Melissa Frischherz}
\IEEEauthorblockA{\textit{AI for Software Engineering, Topic 3} \\
\textit{k12011649 \textfractionsolidus{} SKZ 521}\\
melissa.frischherz@gmail.com}
}

\maketitle
% }}}

% Abstract {{{
% ~~~~~~~~~~~~~~~~~~~~ Abstract ~~~~~~~~~~~~~~~~~~~~
\begin{abstract}
    The quality of source code identifiers has a direct, and measurable impact on program
    comprehension, indirectly influencing validity, maintainability, and security of
    software. This paper proposes a small-scale survey of existing approaches assessing
    the quality of identifiers. Such a measure facilitates the evaluation of naming
    conventions in big code bases, suggestions of context-aware variable, method, or type
    names, or even finding semantic relationships between identifiers across languages and
    programs.

    By leveraging promising advancements in natural language processing (NLP) and machine
    learning, particularly the recent large language models (LLM), to analyze the
    information found in identifiers, we could greatly improve the code analyst's toolkit.
\end{abstract}

\begin{IEEEkeywords}
Machine Learning, Natural Language Processing, Code design, Maintainability, Software
Quality/SQA.
\end{IEEEkeywords}
% }}}

% Introduction {{{
% ~~~~~~~~~~~~~~~~~~~~ Introduction ~~~~~~~~~~~~~~~~~~~~
\section{Introduction}
\label{sec:Introduction}

Identifiers are the smallest unit of semantic information in program source code, yet they
make up the majority of it~\cite{Butler2010Empirical}. This makes them both important to
developers, who need them to comprehend software systems,  and practically indispensable
to nearly all analytical tools~\cite{Gao2019IdentGen}. An empirical study published by
Butler et~al.\@ shows that making poor choices for method, class, and type names
correlates with less readable, maintainable, and overall worse quality
code~\cite{Butler2010Empirical}.

In the following sections, we present a survey of various papers with a focus on
identifiers in the context of software engineering and artificial intelligence. We pay
special attention to papers that attempt to qualitatively assess identifier names, which
opens the path to generating context-dependant identifier suggestions, or finding failures
to adhere to (implicitly) established naming conventions. Section~\ref{sec:Background}
will give some background on the theoretical and technical frameworks,
section~\ref{sec:Methodology} will discuss how we searched for, and selected papers,
section~\ref{sec:Survey} will present the findings of the survey, and finally
sections~\ref{sec:Discussion-and-Future-Work}~and~\ref{sec:Conclusion} will conclude it
with a discussion and ideas for future work.

% }}}

% Background {{{
% ~~~~~~~~~~~~~~~~~~~~ Background ~~~~~~~~~~~~~~~~~~~~
\section{Background}
\label{sec:Background}

% Machine Learning {{{
\subsection{Machine Learning}
\label{ssec:Machine-Learning}

\TODOM{Brief discussions of supervised/unsupervised techniques, neural networks, deep
learning, and RNNs.}

% }}}

% Natural Language Processing {{{
\subsection{Natural Language Processing}
\label{ssec:Natural-Language-Processing}
% }}}

\TODOM{Brief discussions of $n$-grams, grammar, and the attention mechanism.}

\TODOM{EXPLAIN OOV.}

% }}}

% Methodology {{{
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~ Methodology ~~~~~~~~~~~~~~~~~~~~
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Methodology}
\label{sec:Methodology}

We started by establishing an initial overview of the topic landscape, which led us to a
more systematic search of papers pertaining to the ideas discussed in
Section~\ref{sec:Introduction}. This was done by crafting search strings with relevant
keywords for IEEEXplore\footnote{https://ieeexplore.ieee.org} and Google
Scholar\footnote{scholar.google.com}. The search queries we used for both services are as
follows:

\begin{description}[\IEEEsetlabelwidth{Google Scholar:}]
    \item[IEEEXplore:]

    ``(AI OR LLM OR Language Model OR NLP) AND Identifiers AND (Completion OR Analysis OR
    Suggestion)''

    \item[Google Scholar:]

    ``Large Language Models for measuring quality of identifiers in source code''
\end{description}

Of the 190 papers the IEEEXplore query yielded, we hand selected 30 to include in broader
analysis. For the Google Scholar search query, we hand selected 4 papers directly. In
total, we used 34 studies to establish the landscape, and looked further into 8 of them.
Any other papers cited in the work were used for supplemental information.

% }}}

% Survey {{{
% ~~~~~~~~~~~~~~~~~~~~ Survey ~~~~~~~~~~~~~~~~~~~~
\section{Survey}
\label{sec:Survey}

Research into the significance of identifiers in software engineering has been ongoing
since at least 1999, which is the oldest paper in our survey~\cite{Antoniol1999OO}, but
has only recently gained in popularity. A histogram of the years of publication for our
survey papers can be seen in figure~\ref{fig:Histogram-of-Survey-Paper-Publications}. We
suspect this is due to the major improvements in NLP around the time Google released its
paper on the transformer in 2017~\cite{Ashish2017Transformer}, Peters et al.\@ presented
ELMo in the following year~\cite{Peters2018DeepCW}, and finally, BERT was proposed by
Devlin et al.\@ in 2019~\cite{Devlin2019BERT}. This aligns with the big spike in
publications that same year.

\begin{figure}[h!]
    \begin{tikzpicture}
        \begin{axis}[%
            ybar, bar width=5pt, ylabel={\# Publications}, xlabel={Year},
            enlargelimits=0.03,
            symbolic x coords={1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007,%
                               2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,%
                               2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023,%
                               2024
                               }]
            \addplot+[y filter/.expression={y==0 ? nan : y}]%
                table [col sep=comma, header=true]%
                {./data/ext-pubdates.csv};
        \end{axis}
    \end{tikzpicture}

    \caption{Histogram of Survey Paper Publications}
    \label{fig:Histogram-of-Survey-Paper-Publications}
\end{figure}

We have divided the survey into three subsections, one on ``traditional'' algorithmic
approaches, one on approaches using RNNs and LSTMs, and one on very recent advancements
like transformers, and large language models.

% Algorithmic Approaches {{{
\subsection{Algorithmic Approaches}
\label{ssec:Algorithmic-Approaches}

The simplest approach to quantifying the correct naming of identifiers in our survey was
found in the paper by Charitsis et al.\@~\cite{Charitsis2021Assessing}, which focuses on
the skills of computer science students. A reduced syntax backed by the Java programming
language named Karel was used along with student submissions to create a simple,
manually-annotated dataset of function name quality. Students submitted source code for an
identical problem statement in Karel. The submitted code was compiled in-memory and
instrumented, wherein the program state was compared before and after every function
execution to produce a pairwise similarity score of each student function. This similarity
score, along with the manually annotated quality was used to train a discriminator model
producing scores on unseen identifiers. Charitsis et al.\@ report classifier accuracies
between 89.36\% and 76.16\%, depending on the problem hardness.

We also examined a paper which aims to tackle the out of vocabulary problem (see
subsection~\ref{ssec:Natural-Language-Processing})

% }}}

% RNNs and LSTMs {{{
\subsection{RNNs and LSTMs}
\label{ssec:RNNs and LSTMs}
\TODOM{Literature like the LSTM approach of ``A Neural Model for Method Name Generation
from Functional Description'' by Sa Gao et al.\cite{Gao2019IdentGen}}
% }}}

% Transformers, LLMs and Beyond {{{
\subsection{Transformers, LLMs and Beyond}
\label{ssec:LLMs-and-Beyond}
\TODOM{Literature like the LLM approach of ``How Well Can Masked Langauge Models Spot
Identifiers That Violate Naming Guidelines?'' by Johannes Villmow et
al.\cite{Villmow2023Violations}}
% }}}

% }}}

% Discussion and Future Work {{{
% ~~~~~~~~~~~~~~~~~~~~ Discussion and Future Work ~~~~~~~~~~~~~~~~~~~~
\section{Discussion and Future Work}
\label{sec:Discussion-and-Future-Work}

\TODOM{Potential for fully-integrated tools, or CI pipeline utilities. Application of
cutting-edge large language models. Surprising lack of experiments with GPTs?}
% }}}

% Conclusion {{{
% ~~~~~~~~~~~~~~~~~~~~ Conclusion ~~~~~~~~~~~~~~~~~~~~
\section{Conclusion}
\label{sec:Conclusion}

\TODOB
% }}}

% References {{{
% ~~~~~~~~~~~~~~~~~~~~ References ~~~~~~~~~~~~~~~~~~~~

% WARNING: This is a temporary macro to show references before we cite them in the text.
% TODO(Marcel): REMOVE after outline completion
\nocite{*}

\bibliography{IEEEfull,literature}
% }}}

\end{document}
% }}}

% vim: foldmethod=marker
